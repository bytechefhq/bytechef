{"categories":["ARTIFICIAL_INTELLIGENCE"],"customAction":null,"customActionHelp":null,"dataStreamItemReader":null,"dataStreamItemWriter":null,"description":"MiniMax 是领先的通用人工智能科技公司，致力于与用户共创智能。","icon":"path:assets/minimax.svg","tags":null,"metadata":null,"name":"minimax","resources":null,"version":1,"title":"Minimax","actions":[{"batch":null,"dynamicOutput":true,"deprecated":null,"description":"Ask anything you want.","help":null,"metadata":null,"name":"ask","properties":[{"advancedOption":null,"description":"ID of the model to use.","displayCondition":null,"expressionEnabled":null,"hidden":null,"metadata":{},"required":true,"name":"model","type":"STRING","defaultValue":null,"exampleValue":null,"label":"Model","placeholder":null,"controlType":"SELECT","languageId":null,"maxLength":null,"minLength":null,"options":[{"description":null,"label":"abab6.5-chat","value":"abab6.5-chat"},{"description":null,"label":"abab5.5s-chat","value":"abab5.5s-chat"},{"description":null,"label":"abab5.5-chat","value":"abab5.5-chat"},{"description":null,"label":"abab6-chat","value":"abab6-chat"},{"description":null,"label":"abab6.5t-chat","value":"abab6.5t-chat"},{"description":null,"label":"abab6.5s-chat","value":"abab6.5s-chat"},{"description":null,"label":"abab6.5g-chat","value":"abab6.5g-chat"}],"optionsDataSource":null},{"advancedOption":null,"description":"A list of messages comprising the conversation so far.","displayCondition":null,"expressionEnabled":null,"hidden":null,"metadata":{},"required":true,"name":"messages","type":"ARRAY","defaultValue":null,"exampleValue":null,"label":"Messages","placeholder":null,"items":[{"advancedOption":null,"description":null,"displayCondition":null,"expressionEnabled":null,"hidden":null,"metadata":{},"required":null,"name":null,"type":"OBJECT","defaultValue":null,"exampleValue":null,"label":null,"placeholder":null,"additionalProperties":null,"multipleValues":null,"options":null,"properties":[{"advancedOption":null,"description":"The contents of the message.","displayCondition":null,"expressionEnabled":null,"hidden":null,"metadata":{},"required":true,"name":"content","type":"STRING","defaultValue":null,"exampleValue":null,"label":"Content","placeholder":null,"controlType":"TEXT","languageId":null,"maxLength":null,"minLength":null,"options":null,"optionsDataSource":null},{"advancedOption":null,"description":"The role of the messages author","displayCondition":null,"expressionEnabled":null,"hidden":null,"metadata":{},"required":true,"name":"role","type":"STRING","defaultValue":null,"exampleValue":null,"label":"Role","placeholder":null,"controlType":"SELECT","languageId":null,"maxLength":null,"minLength":null,"options":[{"description":null,"label":"system","value":"system"},{"description":null,"label":"user","value":"user"},{"description":null,"label":"assistant","value":"assistant"},{"description":null,"label":"tool","value":"tool"}],"optionsDataSource":null}],"optionsDataSource":null,"controlType":"OBJECT_BUILDER"}],"maxItems":null,"minItems":null,"multipleValues":null,"options":null,"optionsDataSource":null,"controlType":"ARRAY_BUILDER"},{"advancedOption":null,"description":"How many chat completion choices to generate for each input message.","displayCondition":null,"expressionEnabled":null,"hidden":null,"metadata":{},"required":false,"name":"n","type":"INTEGER","defaultValue":1,"exampleValue":null,"label":"Number of chat completion choices","placeholder":null,"maxValue":null,"minValue":null,"options":null,"optionsDataSource":null,"controlType":"INTEGER"},{"advancedOption":null,"description":"Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.","displayCondition":null,"expressionEnabled":null,"hidden":null,"metadata":{},"required":false,"name":"frequencyPenalty","type":"NUMBER","defaultValue":0.0,"exampleValue":null,"label":"Frequency penalty","placeholder":null,"maxNumberPrecision":null,"maxValue":2.0,"minNumberPrecision":null,"minValue":-2.0,"numberPrecision":null,"options":null,"optionsDataSource":null,"controlType":"NUMBER"},{"advancedOption":null,"description":"Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.","displayCondition":null,"expressionEnabled":null,"hidden":null,"metadata":{},"required":false,"name":"presencePenalty","type":"NUMBER","defaultValue":0.0,"exampleValue":null,"label":"Presence penalty","placeholder":null,"maxNumberPrecision":null,"maxValue":2.0,"minNumberPrecision":null,"minValue":-2.0,"numberPrecision":null,"options":null,"optionsDataSource":null,"controlType":"NUMBER"},{"advancedOption":null,"description":"The maximum number of tokens to generate in the chat completion.","displayCondition":null,"expressionEnabled":null,"hidden":null,"metadata":{},"required":false,"name":"maxTokens","type":"INTEGER","defaultValue":null,"exampleValue":null,"label":"Max tokens","placeholder":null,"maxValue":null,"minValue":null,"options":null,"optionsDataSource":null,"controlType":"INTEGER"},{"advancedOption":null,"description":"Controls randomness:  Higher values will make the output more random, while lower values like will make it more focused and deterministic.","displayCondition":null,"expressionEnabled":null,"hidden":null,"metadata":{},"required":false,"name":"temperature","type":"NUMBER","defaultValue":1.0,"exampleValue":null,"label":"Temperature","placeholder":null,"maxNumberPrecision":null,"maxValue":2.0,"minNumberPrecision":null,"minValue":0.0,"numberPrecision":null,"options":null,"optionsDataSource":null,"controlType":"NUMBER"},{"advancedOption":null,"description":"Up to 4 sequences where the API will stop generating further tokens.","displayCondition":null,"expressionEnabled":null,"hidden":null,"metadata":{},"required":false,"name":"stop","type":"ARRAY","defaultValue":null,"exampleValue":null,"label":"Stop","placeholder":null,"items":[{"advancedOption":null,"description":null,"displayCondition":null,"expressionEnabled":null,"hidden":null,"metadata":{},"required":null,"name":null,"type":"STRING","defaultValue":null,"exampleValue":null,"label":null,"placeholder":null,"controlType":"TEXT","languageId":null,"maxLength":null,"minLength":null,"options":null,"optionsDataSource":null}],"maxItems":null,"minItems":null,"multipleValues":null,"options":null,"optionsDataSource":null,"controlType":"ARRAY_BUILDER"},{"advancedOption":null,"description":"An alternative to sampling with temperature, called nucleus sampling,  where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.","displayCondition":null,"expressionEnabled":null,"hidden":null,"metadata":{},"required":false,"name":"topP","type":"NUMBER","defaultValue":1.0,"exampleValue":null,"label":"Top p","placeholder":null,"maxNumberPrecision":null,"maxValue":null,"minNumberPrecision":null,"minValue":null,"numberPrecision":null,"options":null,"optionsDataSource":null,"controlType":"NUMBER"},{"advancedOption":null,"description":"Keeping the same seed would output the same response.","displayCondition":null,"expressionEnabled":null,"hidden":null,"metadata":{},"required":false,"name":"seed","type":"INTEGER","defaultValue":null,"exampleValue":null,"label":"Seed","placeholder":null,"maxValue":null,"minValue":null,"options":null,"optionsDataSource":null,"controlType":"INTEGER"}],"title":"Ask","output":null,"perform":{},"processErrorResponse":null,"outputResponse":{"outputSchema":{"advancedOption":null,"description":null,"displayCondition":null,"expressionEnabled":null,"hidden":null,"metadata":{},"required":null,"name":null,"type":"STRING","defaultValue":null,"exampleValue":null,"label":null,"placeholder":null,"controlType":"TEXT","languageId":null,"maxLength":null,"minLength":null,"options":null,"optionsDataSource":null},"sampleOutput":null},"workflowNodeDescription":null}],"connection":{"authorizations":[{"detectOn":null,"description":null,"name":"bearer_token","properties":[{"advancedOption":null,"description":null,"displayCondition":null,"expressionEnabled":null,"hidden":null,"metadata":{},"required":true,"name":"token","type":"STRING","defaultValue":null,"exampleValue":null,"label":"Token","placeholder":null,"controlType":"TEXT","languageId":null,"maxLength":null,"minLength":null,"options":null,"optionsDataSource":null}],"refreshOn":null,"title":"Bearer Token","type":"BEARER_TOKEN","acquire":null,"apply":null,"authorizationCallback":null,"authorizationUrl":null,"clientId":null,"clientSecret":null,"pkce":null,"refresh":null,"refreshUrl":null,"scopes":null,"refreshToken":null,"tokenUrl":null}],"properties":null,"version":1,"authorizationRequired":null,"baseUri":null,"test":null},"triggers":null}