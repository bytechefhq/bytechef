{"categories":["ARTIFICIAL_INTELLIGENCE"],"customAction":null,"customActionHelp":null,"dataStreamItemReader":null,"dataStreamItemWriter":null,"description":"The LPU Inference Engine by Groq is a hardware and software platform that delivers exceptional compute speed, quality, and energy efficiency.","icon":"path:assets/groq.svg","tags":null,"metadata":null,"name":"groq","resources":null,"version":1,"title":"Groq","actions":[{"batch":null,"dynamicOutput":true,"deprecated":null,"description":"Ask anything you want.","help":null,"metadata":null,"name":"ask","properties":[{"advancedOption":null,"description":"ID of the model to use.","displayCondition":null,"expressionEnabled":null,"hidden":null,"metadata":{},"required":true,"name":"model","type":"STRING","defaultValue":null,"exampleValue":null,"label":"Model","placeholder":null,"controlType":"SELECT","languageId":null,"maxLength":null,"minLength":null,"options":[{"description":null,"label":"gpt-4o-mini","value":"gpt-4o-mini"},{"description":null,"label":"gpt-4","value":"gpt-4"},{"description":null,"label":"gpt-4-0125-preview","value":"gpt-4-0125-preview"},{"description":null,"label":"gpt-3.5-turbo","value":"gpt-3.5-turbo"},{"description":null,"label":"gpt-4-turbo-preview","value":"gpt-4-turbo-preview"},{"description":null,"label":"gpt-4-turbo-2024-04-09","value":"gpt-4-turbo-2024-04-09"},{"description":null,"label":"gpt-4-turbo","value":"gpt-4-turbo"},{"description":null,"label":"gpt-4-32k","value":"gpt-4-32k"},{"description":null,"label":"gpt-3.5-turbo-0125","value":"gpt-3.5-turbo-0125"},{"description":null,"label":"gpt-3.5-turbo-1106","value":"gpt-3.5-turbo-1106"},{"description":null,"label":"gpt-4-vision-preview","value":"gpt-4-vision-preview"},{"description":null,"label":"gpt-4o","value":"gpt-4o"}],"optionsDataSource":null},{"advancedOption":null,"description":"A list of messages comprising the conversation so far.","displayCondition":null,"expressionEnabled":null,"hidden":null,"metadata":{},"required":true,"name":"messages","type":"ARRAY","defaultValue":null,"exampleValue":null,"label":"Messages","placeholder":null,"items":[{"advancedOption":null,"description":null,"displayCondition":null,"expressionEnabled":null,"hidden":null,"metadata":{},"required":null,"name":null,"type":"OBJECT","defaultValue":null,"exampleValue":null,"label":null,"placeholder":null,"additionalProperties":null,"multipleValues":null,"options":null,"properties":[{"advancedOption":null,"description":"The contents of the message.","displayCondition":null,"expressionEnabled":null,"hidden":null,"metadata":{},"required":true,"name":"content","type":"STRING","defaultValue":null,"exampleValue":null,"label":"Content","placeholder":null,"controlType":"TEXT","languageId":null,"maxLength":null,"minLength":null,"options":null,"optionsDataSource":null},{"advancedOption":null,"description":"The role of the messages author","displayCondition":null,"expressionEnabled":null,"hidden":null,"metadata":{},"required":true,"name":"role","type":"STRING","defaultValue":null,"exampleValue":null,"label":"Role","placeholder":null,"controlType":"SELECT","languageId":null,"maxLength":null,"minLength":null,"options":[{"description":null,"label":"system","value":"system"},{"description":null,"label":"user","value":"user"},{"description":null,"label":"assistant","value":"assistant"},{"description":null,"label":"tool","value":"tool"}],"optionsDataSource":null}],"optionsDataSource":null,"controlType":"OBJECT_BUILDER"}],"maxItems":null,"minItems":null,"multipleValues":null,"options":null,"optionsDataSource":null,"controlType":"ARRAY_BUILDER"},{"advancedOption":null,"description":"Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.","displayCondition":null,"expressionEnabled":null,"hidden":null,"metadata":{},"required":false,"name":"frequencyPenalty","type":"NUMBER","defaultValue":0.0,"exampleValue":null,"label":"Frequency penalty","placeholder":null,"maxNumberPrecision":null,"maxValue":2.0,"minNumberPrecision":null,"minValue":-2.0,"numberPrecision":null,"options":null,"optionsDataSource":null,"controlType":"NUMBER"},{"advancedOption":null,"description":"Modify the likelihood of specified tokens appearing in the completion.","displayCondition":null,"expressionEnabled":null,"hidden":null,"metadata":{},"required":false,"name":"logitBias","type":"OBJECT","defaultValue":null,"exampleValue":null,"label":"Logit bias","placeholder":null,"additionalProperties":[{"advancedOption":null,"description":null,"displayCondition":null,"expressionEnabled":null,"hidden":null,"metadata":{},"required":null,"name":null,"type":"NUMBER","defaultValue":null,"exampleValue":null,"label":null,"placeholder":null,"maxNumberPrecision":null,"maxValue":null,"minNumberPrecision":null,"minValue":null,"numberPrecision":null,"options":null,"optionsDataSource":null,"controlType":"NUMBER"}],"multipleValues":null,"options":null,"properties":null,"optionsDataSource":null,"controlType":"OBJECT_BUILDER"},{"advancedOption":null,"description":"The maximum number of tokens to generate in the chat completion.","displayCondition":null,"expressionEnabled":null,"hidden":null,"metadata":{},"required":false,"name":"maxTokens","type":"INTEGER","defaultValue":null,"exampleValue":null,"label":"Max tokens","placeholder":null,"maxValue":null,"minValue":null,"options":null,"optionsDataSource":null,"controlType":"INTEGER"},{"advancedOption":null,"description":"How many chat completion choices to generate for each input message.","displayCondition":null,"expressionEnabled":null,"hidden":null,"metadata":{},"required":false,"name":"n","type":"INTEGER","defaultValue":1,"exampleValue":null,"label":"Number of chat completion choices","placeholder":null,"maxValue":null,"minValue":null,"options":null,"optionsDataSource":null,"controlType":"INTEGER"},{"advancedOption":null,"description":"Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.","displayCondition":null,"expressionEnabled":null,"hidden":null,"metadata":{},"required":false,"name":"presencePenalty","type":"NUMBER","defaultValue":0.0,"exampleValue":null,"label":"Presence penalty","placeholder":null,"maxNumberPrecision":null,"maxValue":2.0,"minNumberPrecision":null,"minValue":-2.0,"numberPrecision":null,"options":null,"optionsDataSource":null,"controlType":"NUMBER"},{"advancedOption":null,"description":"Up to 4 sequences where the API will stop generating further tokens.","displayCondition":null,"expressionEnabled":null,"hidden":null,"metadata":{},"required":false,"name":"stop","type":"ARRAY","defaultValue":null,"exampleValue":null,"label":"Stop","placeholder":null,"items":[{"advancedOption":null,"description":null,"displayCondition":null,"expressionEnabled":null,"hidden":null,"metadata":{},"required":null,"name":null,"type":"STRING","defaultValue":null,"exampleValue":null,"label":null,"placeholder":null,"controlType":"TEXT","languageId":null,"maxLength":null,"minLength":null,"options":null,"optionsDataSource":null}],"maxItems":null,"minItems":null,"multipleValues":null,"options":null,"optionsDataSource":null,"controlType":"ARRAY_BUILDER"},{"advancedOption":null,"description":"Controls randomness:  Higher values will make the output more random, while lower values like will make it more focused and deterministic.","displayCondition":null,"expressionEnabled":null,"hidden":null,"metadata":{},"required":false,"name":"temperature","type":"NUMBER","defaultValue":1.0,"exampleValue":null,"label":"Temperature","placeholder":null,"maxNumberPrecision":null,"maxValue":2.0,"minNumberPrecision":null,"minValue":0.0,"numberPrecision":null,"options":null,"optionsDataSource":null,"controlType":"NUMBER"},{"advancedOption":null,"description":"An alternative to sampling with temperature, called nucleus sampling,  where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.","displayCondition":null,"expressionEnabled":null,"hidden":null,"metadata":{},"required":false,"name":"topP","type":"NUMBER","defaultValue":1.0,"exampleValue":null,"label":"Top p","placeholder":null,"maxNumberPrecision":null,"maxValue":null,"minNumberPrecision":null,"minValue":null,"numberPrecision":null,"options":null,"optionsDataSource":null,"controlType":"NUMBER"},{"advancedOption":null,"description":"A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse.","displayCondition":null,"expressionEnabled":null,"hidden":null,"metadata":{},"required":false,"name":"user","type":"STRING","defaultValue":null,"exampleValue":null,"label":"User","placeholder":null,"controlType":"TEXT","languageId":null,"maxLength":null,"minLength":null,"options":null,"optionsDataSource":null}],"title":"Ask","output":null,"perform":{},"outputResponse":{"outputSchema":{"advancedOption":null,"description":null,"displayCondition":null,"expressionEnabled":null,"hidden":null,"metadata":{},"required":null,"name":null,"type":"STRING","defaultValue":null,"exampleValue":null,"label":null,"placeholder":null,"controlType":"TEXT","languageId":null,"maxLength":null,"minLength":null,"options":null,"optionsDataSource":null},"sampleOutput":null},"processErrorResponse":null,"workflowNodeDescription":null}],"connection":{"authorizations":[{"detectOn":null,"description":null,"name":"bearer_token","properties":[{"advancedOption":null,"description":null,"displayCondition":null,"expressionEnabled":null,"hidden":null,"metadata":{},"required":true,"name":"token","type":"STRING","defaultValue":null,"exampleValue":null,"label":"Token","placeholder":null,"controlType":"TEXT","languageId":null,"maxLength":null,"minLength":null,"options":null,"optionsDataSource":null}],"refreshOn":null,"title":"Bearer Token","type":"BEARER_TOKEN","acquire":null,"apply":null,"authorizationCallback":null,"authorizationUrl":null,"clientId":null,"clientSecret":null,"pkce":null,"refresh":null,"refreshUrl":null,"scopes":null,"refreshToken":null,"tokenUrl":null}],"properties":null,"version":1,"authorizationRequired":null,"baseUri":{},"test":null},"triggers":null}