---
title: "Vertex AI Gemini"
description: "Vertex AI is a fully-managed, unified AI development platform for building and using generative AI."
---


Categories: Artificial Intelligence


Type: vertexGemini/v1

<hr />




## Connections

Version: 1


### Bearer Token

#### Properties

|      Name       |      Label     |     Type     |     Description     | Required |
|:---------------:|:--------------:|:------------:|:-------------------:|:--------:|
| projectId | Project Id | STRING | Google Cloud Platform project ID | true |
| location | Location | STRING <details> <summary> Options </summary> asia-east1, asia-east2, asia-northeast1, asia-northeast3, asia-south1, asia-southeast1, australia-southeast1, europe-central2, europe-north1, europe-southwest1, europe-west1, europe-west2, europe-west3, europe-west4, europe-west6, europe-west8, europe-west9, me-central1, me-central2, me-west1, northamerica-northeast1, southamerica-east1, us-central1, us-east1, us-east4, us-east5, us-south1, us-west1, us-west4 </details> | Region | true |





<hr />


## Actions


### Ask Gemini
Name: ask

`Ask anything you want.`

#### Properties

|      Name       |      Label     |     Type     |     Description     | Required |
|:---------------:|:--------------:|:------------:|:-------------------:|:--------:|
| model | Model | STRING <details> <summary> Options </summary> gemini-1.5-flash-002, gemini-1.5-pro-002, gemini-2.0-flash, gemini-2.0-flash-lite, gemini-2.5-flash-preview-04-17, gemini-2.5-pro-preview-05-06 </details> | ID of the model to use. | true |
| format | Format | STRING <details> <summary> Options </summary> SIMPLE, ADVANCED </details> | Format of providing the prompt to the model. | true |
| userPrompt | Prompt | STRING | User prompt to the model. | true |
| systemPrompt | System Prompt | STRING | System prompt to the model. | false |
| attachments | Attachments | ARRAY <details> <summary> Items </summary> [FILE_ENTRY] </details> | Only text and image files are supported. Also, only certain models supports images. Please check the documentation. | false |
| messages | Messages | ARRAY <details> <summary> Items </summary> [&#123;STRING\(role), STRING\(content), [FILE_ENTRY]\(attachments)&#125;] </details> | A list of messages comprising the conversation so far. | true |
| response | Response | OBJECT <details> <summary> Properties </summary> &#123;STRING\(responseFormat), STRING\(responseSchema)&#125; </details> | The response from the API. | true |
| maxTokens | Max Tokens | INTEGER | The maximum number of tokens to generate in the chat completion. | false |
| n | Candidate Count | INTEGER | The number of generated response messages to return. This value must be between [1, 8], inclusive. Defaults to 1. | false |
| temperature | Temperature | NUMBER | Controls randomness:  Higher values will make the output more random, while lower values like will make it more focused and deterministic. | false |
| topP | Top P | NUMBER | An alternative to sampling with temperature, called nucleus sampling,  where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered. | false |
| topK | Top K | INTEGER | Specify the number of token choices the generative uses to generate the next token. | false |
| stop | Stop | ARRAY <details> <summary> Items </summary> [STRING] </details> | Up to 4 sequences where the API will stop generating further tokens. | false |

#### Example JSON Structure
```json
{
  "label" : "Ask Gemini",
  "name" : "ask",
  "parameters" : {
    "model" : "",
    "format" : "",
    "userPrompt" : "",
    "systemPrompt" : "",
    "attachments" : [ {
      "extension" : "",
      "mimeType" : "",
      "name" : "",
      "url" : ""
    } ],
    "messages" : [ {
      "role" : "",
      "content" : "",
      "attachments" : [ {
        "extension" : "",
        "mimeType" : "",
        "name" : "",
        "url" : ""
      } ]
    } ],
    "response" : {
      "responseFormat" : "",
      "responseSchema" : ""
    },
    "maxTokens" : 1,
    "n" : 1,
    "temperature" : 0.0,
    "topP" : 0.0,
    "topK" : 1,
    "stop" : [ "" ]
  },
  "type" : "vertexGemini/v1/ask"
}
```

#### Output

The output for this action is dynamic and may vary depending on the input parameters. To determine the exact structure of the output, you need to execute the action.






